# CodeValdCortex Environment Configuration
# Copy this file to .env and update values as needed

# =============================================================================
# Server Configuration
# =============================================================================
CVXC_SERVER_PORT=8082
# CVXC_SERVER_HOST=0.0.0.0
# CVXC_LOG_LEVEL=info
# CVXC_LOG_FORMAT=text

# =============================================================================
# Database Configuration (ArangoDB)
# =============================================================================
CVXC_DATABASE_PORT=8529
# CVXC_DATABASE_HOST=localhost
# CVXC_DATABASE_USERNAME=root
CVXC_DATABASE_PASSWORD=
# CVXC_DATABASE_NAME=codevaldcortex

# =============================================================================
# Kubernetes Configuration
# =============================================================================
# CVXC_KUBERNETES_NAMESPACE=default
# CVXC_KUBERNETES_IN_CLUSTER=false
# CVXC_KUBERNETES_CONFIG_PATH=

# =============================================================================
# Agent Configuration
# =============================================================================
# CVXC_AGENT_DEFAULT_IMAGE=codevaldcortex/agent:latest
# CVXC_AGENT_MAX_INSTANCES=100
# CVXC_AGENT_HEALTH_CHECK_PATH=/health

# =============================================================================
# AI Configuration (for AI Agency Designer - MVP-025)
# =============================================================================
# AI Provider: openai, claude, local, or custom
CVXC_AI_PROVIDER=claude
# API Key for OpenAI or Claude (required for cloud providers)
CVXC_AI_API_KEY=
# Model to use (defaults vary by provider)
# OpenAI: gpt-4-turbo-preview, gpt-4, gpt-3.5-turbo
# Claude: claude-3-5-sonnet-20241022, claude-3-opus-20240229
# Local: llama3.1:70b, mistral, etc.
CVXC_AI_MODEL=
# Custom base URL (optional, for custom endpoints or local models)
# OpenAI: https://api.openai.com/v1 (default)
# Claude: https://api.anthropic.com/v1 (default)
# Local: http://localhost:11434 (Ollama default)
CVXC_AI_BASE_URL=
# Temperature (0.0 - 2.0, default: 0.7)
CVXC_AI_TEMPERATURE=0.7
# Max tokens for responses (default: 4096)
CVXC_AI_MAX_TOKENS=4096
# Request timeout in seconds (default: 60)
CVXC_AI_TIMEOUT=60

# =============================================================================
# Notes:
# - Uncommented variables will use values from config.yaml or defaults
# - Sensitive values (passwords, tokens) should NEVER be committed to git
# - Production environments should use secure secret management (e.g., K8s secrets)
# =============================================================================
